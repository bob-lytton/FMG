{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import time, datetime\n",
    "import numpy as np\n",
    "\n",
    "def read_pickle(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        ret = pickle.load(f)\n",
    "    return ret\n",
    "\n",
    "def read_json(file):\n",
    "    with open(file, 'r') as f:\n",
    "        ret = [json.loads(line) for line in f]\n",
    "    return ret\n",
    "\n",
    "def write_pickle(file, data):\n",
    "    with open(file, 'wb') as fw:\n",
    "        pickle.dump(data, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '../yelp_dataset/filtered/'\n",
    "jsonpath = '../yelp_dataset/json/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = read_pickle(filepath+'reviews.pickle')\n",
    "users = read_pickle(filepath+'users.pickle')\n",
    "businesses = read_pickle(filepath+'businesses.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "busi_unfil = read_json(jsonpath+'yelp_academic_dataset_business.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "dict_keys(['business_id', 'cool', 'useful', 'review_id', 'stars', 'funny', 'text', 'date', 'user_id'])\n",
      "742969\n"
     ]
    }
   ],
   "source": [
    "print(type(reviews))\n",
    "print(reviews[0].keys())\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['compliment_list', 'compliment_note', 'compliment_photos', 'compliment_more', 'name', 'elite', 'useful', 'average_stars', 'compliment_cute', 'review_count', 'cool', 'user_id', 'yelping_since', 'funny', 'fans', 'friends', 'compliment_writer', 'compliment_profile', 'compliment_hot', 'compliment_plain', 'compliment_funny', 'compliment_cool'])\n"
     ]
    }
   ],
   "source": [
    "user_unfil = read_json(jsonpath+'yelp_academic_dataset_user.json')\n",
    "print(user_unfil[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['review_count', 'city', 'longitude', 'hours', 'categories', 'name', 'is_open', 'postal_code', 'business_id', 'attributes', 'stars', 'latitude', 'state', 'address'])\n",
      "192609\n",
      "Golf, Active Life\n"
     ]
    }
   ],
   "source": [
    "print(type(busi_unfil[0]))\n",
    "print(busi_unfil[0].keys())\n",
    "print(len(busi_unfil))\n",
    "print(busi_unfil[0]['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "busi_filtered = []\n",
    "for busi in busi_unfil:\n",
    "    for business in businesses:\n",
    "        if busi['business_id'] == business:\n",
    "            busi_filtered.append(busi)\n",
    "            break\n",
    "user_filtered = []\n",
    "for user in user_unfil:\n",
    "    for u in users:\n",
    "        if user['user_id'] == u:\n",
    "            user_filtered.append(user)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(busi_filtered))\n",
    "print(len(businesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uinds = [i for i in range(len(users))]\n",
    "uid2ind = {user:ind for user, ind in zip(users, uinds)}\n",
    "ind2uid = {ind:user for user, ind in zip(users, uinds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_inds = [i for i in range(len(businesses))]\n",
    "bid2ind = {business:ind for business, ind in zip(businesses, b_inds)}\n",
    "ind2bid = {ind:business for business, ind in zip(businesses, b_inds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = set(busi['city'] for busi in busi_filtered)\n",
    "c_inds = [i for i in range(len(cities))]\n",
    "ct_id2ind = {city:ind for city, ind in zip(cities, c_inds)}\n",
    "ind2ct_id = {ind:city for city, ind in zip(cities, c_inds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cities))\n",
    "print(ct_id2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set(category.strip() for busi in busi_filtered for category in busi['categories'].split(','))\n",
    "ca_inds = [i for i in range(len(categories))]\n",
    "ca_id2ind = {category:ind for category, ind in zip(categories, ca_inds)}\n",
    "ind2ca_id = {ind:category for category, ind in zip(categories, ca_inds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(categories))\n",
    "print(ca_id2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = np.zeros((len(users)*len(businesses), 3))\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split(reviews, userid_to_num, businessid_to_num, train_ratio, valid_ratio, test_ratio, n_neg_sample):\n",
    "    selected_reviews = []\n",
    "    \n",
    "    for review in reviews:\n",
    "        filtered_review = {}\n",
    "        filtered_review['user_id'] = userid_to_num[review['user_id']]\n",
    "        filtered_review['business_id'] = businessid_to_num[review['business_id']]\n",
    "        filtered_review['rate'] = 1.0\n",
    "        filtered_review['timestamp'] = time.mktime(datetime.datetime.strptime(review['date'], '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "        selected_reviews.append(filtered_review)\n",
    "        \n",
    "    selected_reviews_sorted = sorted(selected_reviews, key=lambda k: k['timestamp']) # use the earlier data to train and the later data to test\n",
    "    n_reviews = len(selected_reviews_sorted)\n",
    "    train_size = int(n_reviews*train_ratio)\n",
    "    valid_size = int(n_reviews*valid_ratio)\n",
    "    train_data = [selected_reviews_sorted[index] for index in range(train_size)]\n",
    "    valid_data = [selected_reviews_sorted[index] for index in range(train_size, train_size+valid_size)]\n",
    "    test_data = [selected_reviews_sorted[index] for index in range(train_size+valid_size, n_reviews)]\n",
    "    \n",
    "    selected_users = set()\n",
    "    selected_businesses = set()\n",
    "    for review in train_data:\n",
    "        selected_users.add(review['user_id'])\n",
    "        selected_businesses.add(review['business_id'])\n",
    "        \n",
    "    eval_datas = [valid_data, test_data]\n",
    "#     selected_eval_datas = [[] for _ in range(len(eval_datas))]\n",
    "    selected_eval_datas = [[], []]\n",
    "    for eval_index in range(len(eval_datas)):\n",
    "        eval_data = eval_datas[eval_index]\n",
    "        for review in eval_data:\n",
    "            if review['user_id'] in selected_users and review['business_id'] in selected_businesses:\n",
    "                selected_eval_datas[eval_index].append(review)\n",
    "    selected_valid_data, selected_test_data = selected_eval_datas\n",
    "    \n",
    "    data_list = [train_data, selected_valid_data, selected_test_data]\n",
    "#     data_for_user_list = [{} for _ in range(len(data_list))]\n",
    "    data_for_user_list = [{}, {}, {}]\n",
    "    train_data_for_item = set()\n",
    "    for index in range(len(data_list)):\n",
    "        data = data_list[index]\n",
    "        data_for_user = data_for_user_list[index]\n",
    "        for review in data:\n",
    "            user = review['user_id']\n",
    "            item = review['business_id']\n",
    "            if index == 0:\n",
    "                train_data_for_item.add(item)\n",
    "            if user not in data_for_user:\n",
    "                data_for_user[user] = [item]\n",
    "            else:\n",
    "                data_for_user[user].append(item)\n",
    "    train_data_for_user, valid_data_for_user, test_data_for_user = data_for_user_list # dictionary of user_id:[item_id]\n",
    "    \n",
    "    with_neg_list = [valid_data_for_user, test_data_for_user]\n",
    "#     data_with_neg_list = [[] for _ in range(len(with_neg_list))]\n",
    "    data_with_neg_list = [[], []]\n",
    "    for index in range(len(with_neg_list)):\n",
    "        current_data = with_neg_list[index]\n",
    "        for user in current_data.keys():\n",
    "            if user not in selected_users:\n",
    "                continue\n",
    "            user_eval = {} # a dict\n",
    "            business_set = selected_businesses - set(train_data_for_user[user]) - set(current_data[user]) # items not existed in this user's records\n",
    "            sample_businesses = np.random.choice(list(business_set), size=n_neg_sample, replace=False)    # sample is random.choice\n",
    "            user_eval['user_id'] = user\n",
    "            user_eval['pos_business_id'] = current_data[user]\n",
    "            user_eval['neg_business_id'] = list(sample_businesses)\n",
    "            data_with_neg_list[index].append(user_eval)\n",
    "    valid_with_neg, test_with_neg = data_with_neg_list\n",
    "    \n",
    "    return train_data, selected_valid_data, selected_test_data, valid_with_neg, test_with_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get adjs\n",
    "def get_adj_matrix(uid2ind, bid2ind, city_id2ind, cat_id2ind, users, businesses, reviews):\n",
    "    \"\"\"\n",
    "    metapaths: UB, UUB, UBUB, UBCaB, UBCiB\n",
    "    \"\"\"\n",
    "    tot_users = len(uid2ind)  # tot for total\n",
    "    tot_business = len(bid2ind)\n",
    "    tot_city = len(city_id2ind)\n",
    "    tot_category = len(cat_id2ind)\n",
    "    print(tot_users, tot_business, tot_city, tot_category)\n",
    "    #relation U-U\n",
    "    adj_UU = np.zeros([tot_users, tot_users])\n",
    "    adj_UB = np.zeros([tot_users, tot_business])\n",
    "    adj_BCa = np.zeros([tot_business, tot_category])\n",
    "    adj_BCi = np.zeros([tot_business, tot_city])\n",
    "    print(adj_BCi.shape)\n",
    "    for user in users:\n",
    "        if user['user_id'] not in uid2ind:\n",
    "            continue\n",
    "        user_id = uid2ind[user['user_id']]\n",
    "        for friend in user['friends'].split(','):\n",
    "            friend = friend.strip()\n",
    "            if friend in uid2ind:\n",
    "                friend_id = uid2ind[friend]\n",
    "                adj_UU[user_id][friend_id] = 1\n",
    "                adj_UU[friend_id][user_id] = 1\n",
    "    #relation U-P-B\n",
    "    for review in reviews:\n",
    "        user_id = uid2ind[review['user_id']]\n",
    "        business_id = bid2ind[review['business_id']]\n",
    "        adj_UB[user_id][business_id] = 1\n",
    "    #relation B_Ca B_Ci\n",
    "    for business in businesses:\n",
    "        if business['business_id'] not in bid2ind:\n",
    "            continue\n",
    "        business_id = bid2ind[business['business_id']]\n",
    "        city_id = city_id2ind[business['city']]\n",
    "        print(\"business_id: %d, city_id: %d\" % (business_id, city_id))\n",
    "        adj_BCi[business_id][city_id] = 1\n",
    "        \n",
    "        # more than one category for a business\n",
    "        for category in business['categories'].split(','):\n",
    "            category = category.strip()\n",
    "            category_id = cat_id2ind[category]\n",
    "            adj_BCa[business_id][category_id] = 1\n",
    "\n",
    "    #metapath\n",
    "    adj_UUB = adj_UU.dot(adj_UB)\n",
    "\n",
    "    adj_UBU = adj_UB.dot(adj_UB.T)\n",
    "\n",
    "    adj_UBUB = adj_UBU.dot(adj_UB)\n",
    "\n",
    "    adj_UBCa = adj_UB.dot(adj_BCa)\n",
    "    adj_UBCaB = adj_UBCa.dot(adj_BCa.T)\n",
    "\n",
    "    adj_UBCi = adj_UB.dot(adj_BCi)\n",
    "    adj_UBCiB = adj_UBCi.dot(adj_BCi.T)\n",
    "\n",
    "#     adj_UCaB = adj_UCa.dot(adj_CaB)\n",
    "    \n",
    "#     adj_UCiB = adj_UCi.dot(adj_CiB)\n",
    "    \n",
    "    return adj_UB, adj_UUB, adj_UBUB, adj_UBCaB, adj_UBCiB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, valid_with_neg_sample, test_with_neg_sample \\\n",
    "    = dataset_split(reviews, uid2ind, bid2ind, 0.8, 0.1, 0.1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../yelp_dataset/rates/'\n",
    "filenames = ['train_data', 'valid_data', 'test_data', 'valid_with_neg_sample', 'test_with_neg_sample']\n",
    "objs = [train_data, valid_data, test_data, valid_with_neg_sample, test_with_neg_sample]\n",
    "for file, obj in zip(filenames, objs):\n",
    "    write_pickle(path+file+'.pickle', obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get adj matrices\n",
    "adj_UB, adj_UUB, adj_UBUB, adj_UBCaB, adj_UBCiB \\\n",
    "    = get_adj_matrix(uid2ind, bid2ind, ct_id2ind, ca_id2ind, user_filtered, busi_filtered, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adj_UB.shape)\n",
    "print(adj_UBCaB.shape)\n",
    "print(adj_UBCaB[0:100][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs = [adj_UB, adj_UUB, adj_UBUB, adj_UBCaB, adj_UBCiB]\n",
    "filenames = ['adj_UB', 'adj_UUB', 'adj_UBUB', 'adj_UBCaB', 'adj_UBCiB']\n",
    "path = '../yelp_dataset/adjs/'\n",
    "for adj, file in zip(adjs, filenames):\n",
    "    write_pickle(path+file+'.pickle', adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['uid2ind', 'bid2ind', 'ct_id2ind', 'ca_id2ind', 'ind2uid', 'ind2bid', 'ind2ct_id', 'ind2ca_id']\n",
    "maps = [uid2ind, bid2ind, ct_id2ind, ca_id2ind, ind2uid, ind2bid, ind2ct_id, ind2ca_id]\n",
    "path = '../yelp_dataset/adjs/'\n",
    "for mapping, file in zip(maps, filenames):\n",
    "    write_pickle(path+file+'.pickle', mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dictionaries\n",
    "path = '../yelp_dataset/adjs/'\n",
    "uid2ind = read_pickle(path+'uid2ind.pickle')\n",
    "bid2ind = read_pickle(path+'bid2ind.pickle')\n",
    "ct_id2ind = read_pickle(path+'ct_id2ind.pickle')\n",
    "ca_id2ind = read_pickle(path+'ca_id2ind.pickle')\n",
    "ind2uid = read_pickle(path+'ind2uid.pickle')\n",
    "ind2bid = read_pickle(path+'ind2bid.pickle')\n",
    "ind2ct_id = read_pickle(path+'ind2ct_id.pickle')\n",
    "ind2ca_id = read_pickle(path+'ind2ca_id.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tensorflow-2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
